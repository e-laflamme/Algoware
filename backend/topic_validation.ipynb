{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install cohere python-dotenv tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cohere\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# load the .env file and get the API key\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "# check if key is loaded\n",
    "if api_key:\n",
    "    print(\"API key loaded successfully.\")\n",
    "else:\n",
    "    print(\"API key not found. Make sure .env file is present and contains COHERE_API_KEY.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.Client(api_key)\n",
    "print(\"Cohere client initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load your dataset (update path if needed)\n",
    "csv_path = \"../data/youtube_transcripts.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# drop rows with missing important values\n",
    "df = df.dropna(subset=[\"topic\", \"title\", \"transcript\"]).reset_index(drop=True)\n",
    "\n",
    "print(f\"Loaded dataset with {len(df)} entries after cleaning.\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "# truncate transcript to avoid token limit issues\n",
    "def truncate(text, max_chars=1500):\n",
    "    return text if len(text) <= max_chars else text[:max_chars]\n",
    "\n",
    "# validate topic using cohere.chat()\n",
    "def validate_topic(title, transcript, topic, retries=3, delay=0.4):\n",
    "    prompt = f\"\"\"\n",
    "You are helping validate whether YouTube videos are correctly labeled.\n",
    "\n",
    "Video Title: \"{title}\"\n",
    "\n",
    "Transcript:\n",
    "\\\"\\\"\\\"\n",
    "{truncate(transcript)}\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "The expected topic of this video is: {topic}\n",
    "\n",
    "Does the content of the video (based on title and transcript) actually appear to be about this topic?\n",
    "\n",
    "Respond ONLY with \"Yes\" or \"No\".\n",
    "\"\"\".strip()\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = co.chat(\n",
    "                model=\"command-r\",\n",
    "                message=prompt,\n",
    "                temperature=0.2,\n",
    "            )\n",
    "            answer = response.text.strip().lower()\n",
    "            time.sleep(delay + random.uniform(0.1, 0.3))\n",
    "\n",
    "            if \"yes\" in answer:\n",
    "                return \"Yes\"\n",
    "            elif \"no\" in answer:\n",
    "                return \"No\"\n",
    "            else:\n",
    "                return \"Unclear\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error on attempt {attempt + 1}: {e}\")\n",
    "            time.sleep(1.5)\n",
    "\n",
    "    return \"Error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply validation across dataset\n",
    "tqdm.pandas()\n",
    "print(\"Validating topics using Cohere. This may take a few minutes depending on dataset size...\")\n",
    "df[\"matches_topic\"] = df.progress_apply(\n",
    "    lambda row: validate_topic(row[\"title\"], row[\"transcript\"], row[\"topic\"]),\n",
    "    axis=1\n",
    ")\n",
    "print(\"Topic validation completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter to keep only relevant rows\n",
    "df_cleaned = df[df[\"matches_topic\"] == \"Yes\"]\n",
    "\n",
    "# save cleaned dataset\n",
    "output_path = \"../data/cleaned_youtube_dataset.csv\"\n",
    "df_cleaned.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved cleaned dataset with {len(df_cleaned)} rows to {output_path}\")\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rejected = df[df[\"matches_topic\"] == \"No\"]\n",
    "df_rejected.to_csv(\"../data/rejected_youtube_dataset.csv\", index=False)\n",
    "\n",
    "print(f\"Saved {len(df_rejected)} rejected rows to rejected_youtube_dataset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
